{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns            # visualization tool\n",
    "import matplotlib.cm as cm       #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_csv(file_name,k):\n",
    "    data = pd.read_csv('/home/amaya/emp/Realtime-Sign-Language-Translation-to-Speech-DNN/all/User'+str(k)+'/'+file_name)\n",
    "    global classes\n",
    "    \n",
    "    class_ = file_name[0:len(file_name)-14]\n",
    "    \n",
    "    # print(data.head(2))\n",
    "\n",
    "    columns = list(data.columns)[1:]\n",
    "    # features = ['MAV','RMS','VAR','SSI','MAX','MIN']\n",
    "    \n",
    "    vector = []\n",
    "    # global out_columns\n",
    "    \n",
    "    for item in columns:\n",
    "        temp = list(data[item])\n",
    "        # calculating MAV ***\n",
    "        # out_columns.append(item+features[0])\n",
    "        abs_val = list(map(abs,temp))\n",
    "        vector.append(np.mean(abs_val))\n",
    "\n",
    "        # calculating RMS ***\n",
    "        # out_columns.append(item+features[1])\n",
    "        vector.append(np.sqrt(np.mean(np.array(temp)**2)))\n",
    "\n",
    "        # calculate variance ***\n",
    "        # out_columns.append(item+features[2])\n",
    "        x_mean = np.mean(temp)\n",
    "        dif = temp - x_mean\n",
    "        vector.append(np.mean(np.array(dif)**2))\n",
    "\n",
    "        # calculating ssi ***\n",
    "        # out_columns.append(item+features[3])\n",
    "        vector.append(np.sum(np.array(temp)**2))\n",
    "\n",
    "        # calculating max ***\n",
    "        # out_columns.append(item+features[4])\n",
    "        vector.append(max(temp))\n",
    "\n",
    "        # calculating min ***\n",
    "        # out_columns.append(item+features[5])\n",
    "        vector.append(min(temp))\n",
    "        \n",
    "    if class_ in classes:\n",
    "        vector.append(classes.index(class_))\n",
    "    else:\n",
    "        classes.append(class_)\n",
    "        vector.append(classes.index(class_))\n",
    "        \n",
    "    return vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_columns = ['EMG0LMAV', 'EMG0LRMS', 'EMG0LVAR', 'EMG0LSSI', 'EMG0LMAX', 'EMG0LMIN', 'EMG1LMAV', 'EMG1LRMS', 'EMG1LVAR', 'EMG1LSSI', 'EMG1LMAX', 'EMG1LMIN', 'EMG2LMAV', 'EMG2LRMS', 'EMG2LVAR', 'EMG2LSSI', 'EMG2LMAX', 'EMG2LMIN', 'EMG3LMAV', 'EMG3LRMS', 'EMG3LVAR', 'EMG3LSSI', 'EMG3LMAX', 'EMG3LMIN', 'EMG4LMAV', 'EMG4LRMS', 'EMG4LVAR', 'EMG4LSSI', 'EMG4LMAX', 'EMG4LMIN', 'EMG5LMAV', 'EMG5LRMS', 'EMG5LVAR', 'EMG5LSSI', 'EMG5LMAX', 'EMG5LMIN', 'EMG6LMAV', 'EMG6LRMS', 'EMG6LVAR', 'EMG6LSSI', 'EMG6LMAX', 'EMG6LMIN', 'EMG7LMAV', 'EMG7LRMS', 'EMG7LVAR', 'EMG7LSSI', 'EMG7LMAX', 'EMG7LMIN', 'AXLMAV', 'AXLRMS', 'AXLVAR', 'AXLSSI', 'AXLMAX', 'AXLMIN', 'AYLMAV', 'AYLRMS', 'AYLVAR', 'AYLSSI', 'AYLMAX', 'AYLMIN', 'AZLMAV', 'AZLRMS', 'AZLVAR', 'AZLSSI', 'AZLMAX', 'AZLMIN', 'GXLMAV', 'GXLRMS', 'GXLVAR', 'GXLSSI', 'GXLMAX', 'GXLMIN', 'GYLMAV', 'GYLRMS', 'GYLVAR', 'GYLSSI', 'GYLMAX', 'GYLMIN', 'GZLMAV', 'GZLRMS', 'GZLVAR', 'GZLSSI', 'GZLMAX', 'GZLMIN', 'ORLMAV', 'ORLRMS', 'ORLVAR', 'ORLSSI', 'ORLMAX', 'ORLMIN', 'OPLMAV', 'OPLRMS', 'OPLVAR', 'OPLSSI', 'OPLMAX', 'OPLMIN', 'OYLMAV', 'OYLRMS', 'OYLVAR', 'OYLSSI', 'OYLMAX', 'OYLMIN', 'EMG0RMAV', 'EMG0RRMS', 'EMG0RVAR', 'EMG0RSSI', 'EMG0RMAX', 'EMG0RMIN', 'EMG1RMAV', 'EMG1RRMS', 'EMG1RVAR', 'EMG1RSSI', 'EMG1RMAX', 'EMG1RMIN', 'EMG2RMAV', 'EMG2RRMS', 'EMG2RVAR', 'EMG2RSSI', 'EMG2RMAX', 'EMG2RMIN', 'EMG3RMAV', 'EMG3RRMS', 'EMG3RVAR', 'EMG3RSSI', 'EMG3RMAX', 'EMG3RMIN', 'EMG4RMAV', 'EMG4RRMS', 'EMG4RVAR', 'EMG4RSSI', 'EMG4RMAX', 'EMG4RMIN', 'EMG5RMAV', 'EMG5RRMS', 'EMG5RVAR', 'EMG5RSSI', 'EMG5RMAX', 'EMG5RMIN', 'EMG6RMAV', 'EMG6RRMS', 'EMG6RVAR', 'EMG6RSSI', 'EMG6RMAX', 'EMG6RMIN', 'EMG7RMAV', 'EMG7RRMS', 'EMG7RVAR', 'EMG7RSSI', 'EMG7RMAX', 'EMG7RMIN', 'AXRMAV', 'AXRRMS', 'AXRVAR', 'AXRSSI', 'AXRMAX', 'AXRMIN', 'AYRMAV', 'AYRRMS', 'AYRVAR', 'AYRSSI', 'AYRMAX', 'AYRMIN', 'AZRMAV', 'AZRRMS', 'AZRVAR', 'AZRSSI', 'AZRMAX', 'AZRMIN', 'GXRMAV', 'GXRRMS', 'GXRVAR', 'GXRSSI', 'GXRMAX', 'GXRMIN', 'GYRMAV', 'GYRRMS', 'GYRVAR', 'GYRSSI', 'GYRMAX', 'GYRMIN', 'GZRMAV', 'GZRRMS', 'GZRVAR', 'GZRSSI', 'GZRMAX', 'GZRMIN', 'ORRMAV', 'ORRRMS', 'ORRVAR', 'ORRSSI', 'ORRMAX', 'ORRMIN', 'OPRMAV', 'OPRRMS', 'OPRVAR', 'OPRSSI', 'OPRMAX', 'OPRMIN', 'OYRMAV', 'OYRRMS', 'OYRVAR', 'OYRSSI', 'OYRMAX', 'OYRMIN','CLASS']\n",
    "# 205 columns (34*6 + 1)\n",
    "output = []\n",
    "classes=[]\n",
    "# print(len(out_columns))\n",
    "\n",
    "# process_one_csv(files[0])\n",
    "for k in range(1,11):\n",
    "    if(k!=5):\n",
    "        files = os.listdir('/home/amaya/emp/Realtime-Sign-Language-Translation-to-Speech-DNN/all/User'+str(k)+'/')\n",
    "    else:\n",
    "        continue\n",
    "    for file in files:\n",
    "        if(file[-1] == 'v'):      # to avoid _DS_STORE files and anyother hiiden files\n",
    "            output.append(process_one_csv(file,k))\n",
    "        \n",
    "processed = pd.DataFrame(output,columns = out_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling of data\n",
    "scaler = preprocessing.MinMaxScaler()   # since the data set is not gaussian\n",
    "scaled_df = scaler.fit_transform(processed[out_columns[:len(out_columns)-1]])\n",
    "X = pd.DataFrame(scaled_df, columns = out_columns[:len(out_columns)-1])\n",
    "y = processed['CLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0822 23:44:36.276560 140339846211328 deprecation.py:506] From /home/amaya/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# setting up the layers\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(204,input_dim = 204,activation = 'relu'),\n",
    "    keras.layers.Dense(204,activation = 'relu'),\n",
    "    keras.layers.Dense(20,activation = 'softmax')\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "440/440 [==============================] - 0s 284us/sample - loss: 2.9218 - acc: 0.0909\n",
      "Epoch 2/100\n",
      "440/440 [==============================] - 0s 63us/sample - loss: 2.5959 - acc: 0.2977\n",
      "Epoch 3/100\n",
      "440/440 [==============================] - 0s 64us/sample - loss: 2.2524 - acc: 0.3568\n",
      "Epoch 4/100\n",
      "440/440 [==============================] - 0s 66us/sample - loss: 1.9602 - acc: 0.4545\n",
      "Epoch 5/100\n",
      "440/440 [==============================] - 0s 66us/sample - loss: 1.7296 - acc: 0.5114\n",
      "Epoch 6/100\n",
      "440/440 [==============================] - 0s 70us/sample - loss: 1.5560 - acc: 0.5591\n",
      "Epoch 7/100\n",
      "440/440 [==============================] - 0s 71us/sample - loss: 1.3991 - acc: 0.5864\n",
      "Epoch 8/100\n",
      "440/440 [==============================] - 0s 79us/sample - loss: 1.2370 - acc: 0.6455\n",
      "Epoch 9/100\n",
      "440/440 [==============================] - 0s 73us/sample - loss: 1.1469 - acc: 0.6636\n",
      "Epoch 10/100\n",
      "440/440 [==============================] - 0s 80us/sample - loss: 1.0694 - acc: 0.6750\n",
      "Epoch 11/100\n",
      "440/440 [==============================] - 0s 80us/sample - loss: 0.9899 - acc: 0.7045\n",
      "Epoch 12/100\n",
      "440/440 [==============================] - 0s 69us/sample - loss: 0.9149 - acc: 0.7409\n",
      "Epoch 13/100\n",
      "440/440 [==============================] - 0s 68us/sample - loss: 0.8333 - acc: 0.7750\n",
      "Epoch 14/100\n",
      "440/440 [==============================] - 0s 67us/sample - loss: 0.8317 - acc: 0.7477\n",
      "Epoch 15/100\n",
      "440/440 [==============================] - 0s 74us/sample - loss: 0.7968 - acc: 0.7568\n",
      "Epoch 16/100\n",
      "440/440 [==============================] - 0s 70us/sample - loss: 0.7583 - acc: 0.7455\n",
      "Epoch 17/100\n",
      "440/440 [==============================] - 0s 79us/sample - loss: 0.6688 - acc: 0.8091\n",
      "Epoch 18/100\n",
      "440/440 [==============================] - 0s 69us/sample - loss: 0.6225 - acc: 0.8045\n",
      "Epoch 19/100\n",
      "440/440 [==============================] - 0s 79us/sample - loss: 0.5615 - acc: 0.8409\n",
      "Epoch 20/100\n",
      "440/440 [==============================] - 0s 79us/sample - loss: 0.5764 - acc: 0.8227\n",
      "Epoch 21/100\n",
      "440/440 [==============================] - 0s 71us/sample - loss: 0.5115 - acc: 0.8682\n",
      "Epoch 22/100\n",
      "440/440 [==============================] - 0s 66us/sample - loss: 0.4744 - acc: 0.8909\n",
      "Epoch 23/100\n",
      "440/440 [==============================] - 0s 81us/sample - loss: 0.4397 - acc: 0.9159\n",
      "Epoch 24/100\n",
      "440/440 [==============================] - 0s 92us/sample - loss: 0.4442 - acc: 0.8795\n",
      "Epoch 25/100\n",
      "440/440 [==============================] - 0s 71us/sample - loss: 0.4051 - acc: 0.9045\n",
      "Epoch 26/100\n",
      "440/440 [==============================] - 0s 67us/sample - loss: 0.3747 - acc: 0.9136\n",
      "Epoch 27/100\n",
      "440/440 [==============================] - 0s 66us/sample - loss: 0.3514 - acc: 0.9295\n",
      "Epoch 28/100\n",
      "440/440 [==============================] - 0s 69us/sample - loss: 0.3381 - acc: 0.9159\n",
      "Epoch 29/100\n",
      "440/440 [==============================] - 0s 75us/sample - loss: 0.3356 - acc: 0.9318\n",
      "Epoch 30/100\n",
      "440/440 [==============================] - 0s 84us/sample - loss: 0.2995 - acc: 0.9500\n",
      "Epoch 31/100\n",
      "440/440 [==============================] - 0s 87us/sample - loss: 0.2902 - acc: 0.9341\n",
      "Epoch 32/100\n",
      "440/440 [==============================] - 0s 80us/sample - loss: 0.2847 - acc: 0.9273\n",
      "Epoch 33/100\n",
      "440/440 [==============================] - 0s 69us/sample - loss: 0.2370 - acc: 0.9727\n",
      "Epoch 34/100\n",
      "440/440 [==============================] - 0s 71us/sample - loss: 0.2628 - acc: 0.9364\n",
      "Epoch 35/100\n",
      "440/440 [==============================] - 0s 70us/sample - loss: 0.2670 - acc: 0.9227\n",
      "Epoch 36/100\n",
      "440/440 [==============================] - 0s 69us/sample - loss: 0.2582 - acc: 0.9341\n",
      "Epoch 37/100\n",
      "440/440 [==============================] - 0s 73us/sample - loss: 0.2177 - acc: 0.9523\n",
      "Epoch 38/100\n",
      "440/440 [==============================] - 0s 73us/sample - loss: 0.2133 - acc: 0.9659\n",
      "Epoch 39/100\n",
      "440/440 [==============================] - 0s 88us/sample - loss: 0.1913 - acc: 0.9614\n",
      "Epoch 40/100\n",
      "440/440 [==============================] - 0s 75us/sample - loss: 0.1629 - acc: 0.9795\n",
      "Epoch 41/100\n",
      "440/440 [==============================] - 0s 75us/sample - loss: 0.1740 - acc: 0.9750\n",
      "Epoch 42/100\n",
      "440/440 [==============================] - 0s 69us/sample - loss: 0.1692 - acc: 0.9682\n",
      "Epoch 43/100\n",
      "440/440 [==============================] - 0s 66us/sample - loss: 0.1533 - acc: 0.9841\n",
      "Epoch 44/100\n",
      "440/440 [==============================] - 0s 70us/sample - loss: 0.1370 - acc: 0.9864\n",
      "Epoch 45/100\n",
      "440/440 [==============================] - 0s 82us/sample - loss: 0.1208 - acc: 0.9886\n",
      "Epoch 46/100\n",
      "440/440 [==============================] - 0s 67us/sample - loss: 0.1203 - acc: 0.9886\n",
      "Epoch 47/100\n",
      "440/440 [==============================] - 0s 67us/sample - loss: 0.1202 - acc: 0.9841\n",
      "Epoch 48/100\n",
      "440/440 [==============================] - 0s 67us/sample - loss: 0.1072 - acc: 0.9886\n",
      "Epoch 49/100\n",
      "440/440 [==============================] - 0s 67us/sample - loss: 0.0943 - acc: 0.9977\n",
      "Epoch 50/100\n",
      "440/440 [==============================] - 0s 67us/sample - loss: 0.0944 - acc: 0.9909\n",
      "Epoch 51/100\n",
      "440/440 [==============================] - 0s 86us/sample - loss: 0.0916 - acc: 0.9932\n",
      "Epoch 52/100\n",
      "440/440 [==============================] - 0s 94us/sample - loss: 0.0963 - acc: 0.9886\n",
      "Epoch 53/100\n",
      "440/440 [==============================] - 0s 66us/sample - loss: 0.0801 - acc: 0.9955\n",
      "Epoch 54/100\n",
      "440/440 [==============================] - 0s 66us/sample - loss: 0.0751 - acc: 0.9977\n",
      "Epoch 55/100\n",
      "440/440 [==============================] - 0s 66us/sample - loss: 0.0714 - acc: 0.9977\n",
      "Epoch 56/100\n",
      "440/440 [==============================] - 0s 68us/sample - loss: 0.0666 - acc: 0.9977\n",
      "Epoch 57/100\n",
      "440/440 [==============================] - 0s 73us/sample - loss: 0.0722 - acc: 0.9955\n",
      "Epoch 58/100\n",
      "440/440 [==============================] - 0s 67us/sample - loss: 0.0716 - acc: 0.9955\n",
      "Epoch 59/100\n",
      "440/440 [==============================] - 0s 68us/sample - loss: 0.0729 - acc: 0.9932\n",
      "Epoch 60/100\n",
      "440/440 [==============================] - 0s 73us/sample - loss: 0.0567 - acc: 0.9977\n",
      "Epoch 61/100\n",
      "440/440 [==============================] - 0s 66us/sample - loss: 0.0496 - acc: 0.9977\n",
      "Epoch 62/100\n",
      "440/440 [==============================] - 0s 77us/sample - loss: 0.0489 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "440/440 [==============================] - 0s 68us/sample - loss: 0.0497 - acc: 0.9977\n",
      "Epoch 64/100\n",
      "440/440 [==============================] - 0s 74us/sample - loss: 0.0517 - acc: 0.9977\n",
      "Epoch 65/100\n",
      "440/440 [==============================] - 0s 71us/sample - loss: 0.0502 - acc: 0.9955\n",
      "Epoch 66/100\n",
      "440/440 [==============================] - 0s 78us/sample - loss: 0.0522 - acc: 0.9955\n",
      "Epoch 67/100\n",
      "440/440 [==============================] - 0s 77us/sample - loss: 0.0399 - acc: 0.9977\n",
      "Epoch 68/100\n",
      "440/440 [==============================] - 0s 73us/sample - loss: 0.0428 - acc: 0.9977\n",
      "Epoch 69/100\n",
      "440/440 [==============================] - 0s 79us/sample - loss: 0.0382 - acc: 0.9977\n",
      "Epoch 70/100\n",
      "440/440 [==============================] - 0s 63us/sample - loss: 0.0331 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "440/440 [==============================] - 0s 63us/sample - loss: 0.0327 - acc: 0.9977\n",
      "Epoch 72/100\n",
      "440/440 [==============================] - 0s 68us/sample - loss: 0.0340 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "440/440 [==============================] - 0s 68us/sample - loss: 0.0293 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "440/440 [==============================] - 0s 71us/sample - loss: 0.0295 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "440/440 [==============================] - 0s 67us/sample - loss: 0.0317 - acc: 0.9977\n",
      "Epoch 76/100\n",
      "440/440 [==============================] - 0s 70us/sample - loss: 0.0294 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "440/440 [==============================] - 0s 66us/sample - loss: 0.0284 - acc: 0.9977\n",
      "Epoch 78/100\n",
      "440/440 [==============================] - 0s 79us/sample - loss: 0.0282 - acc: 0.9977\n",
      "Epoch 79/100\n",
      "440/440 [==============================] - 0s 65us/sample - loss: 0.0265 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "440/440 [==============================] - 0s 66us/sample - loss: 0.0268 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "440/440 [==============================] - 0s 68us/sample - loss: 0.0264 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "440/440 [==============================] - 0s 81us/sample - loss: 0.0276 - acc: 0.9977\n",
      "Epoch 83/100\n",
      "440/440 [==============================] - 0s 79us/sample - loss: 0.0227 - acc: 0.9977\n",
      "Epoch 84/100\n",
      "440/440 [==============================] - 0s 81us/sample - loss: 0.0215 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "440/440 [==============================] - 0s 72us/sample - loss: 0.0206 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "440/440 [==============================] - 0s 76us/sample - loss: 0.0190 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "440/440 [==============================] - 0s 68us/sample - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "440/440 [==============================] - 0s 71us/sample - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "440/440 [==============================] - 0s 83us/sample - loss: 0.0228 - acc: 0.9955\n",
      "Epoch 90/100\n",
      "440/440 [==============================] - 0s 86us/sample - loss: 0.0244 - acc: 0.9977\n",
      "Epoch 91/100\n",
      "440/440 [==============================] - 0s 85us/sample - loss: 0.0217 - acc: 0.9977\n",
      "Epoch 92/100\n",
      "440/440 [==============================] - 0s 71us/sample - loss: 0.0166 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "440/440 [==============================] - 0s 67us/sample - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "440/440 [==============================] - 0s 73us/sample - loss: 0.0142 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "440/440 [==============================] - 0s 69us/sample - loss: 0.0138 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "440/440 [==============================] - 0s 70us/sample - loss: 0.0135 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "440/440 [==============================] - 0s 68us/sample - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "440/440 [==============================] - 0s 70us/sample - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "440/440 [==============================] - 0s 78us/sample - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "440/440 [==============================] - 0s 72us/sample - loss: 0.0121 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa2df9e7fd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,y_train,epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 0s 273us/sample - loss: 0.5300 - acc: 0.8909\n",
      "0.8909091\n"
     ]
    }
   ],
   "source": [
    "# evaluate accuracy\n",
    "test_loss,test_acc = model.evaluate(X_test,y_test)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "0\n",
      "19\n",
      "0\n",
      "2\n",
      "14\n",
      "18\n",
      "6\n",
      "9\n",
      "5\n",
      "9\n",
      "0\n",
      "12\n",
      "12\n",
      "9\n",
      "16\n",
      "12\n",
      "10\n",
      "17\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predictions = model.predict(X_test)\n",
    "for i in range(20):\n",
    "    print(np.argmax(predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "0\n",
      "19\n",
      "0\n",
      "2\n",
      "14\n",
      "18\n",
      "1\n",
      "10\n",
      "17\n",
      "10\n",
      "0\n",
      "9\n",
      "12\n",
      "9\n",
      "16\n",
      "9\n",
      "10\n",
      "17\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(list(y_test)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
