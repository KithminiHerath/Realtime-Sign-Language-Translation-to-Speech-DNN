{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns            # visualization tool\n",
    "import matplotlib.cm as cm       #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_crossing(temp,threshold):\n",
    "    zc = 0\n",
    "    for i in range(len(temp)-1):\n",
    "        if((temp[i]*temp[i+1]) < 0 and abs(temp[i]-temp[i+1]) >= threshold):\n",
    "            zc += 1\n",
    "    return zc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_csv(file_name,k):\n",
    "    data = pd.read_csv('/home/amaya/emp/Realtime-Sign-Language-Translation-to-Speech-DNN/all/User'+str(k)+'/'+file_name)\n",
    "    global classes\n",
    "    \n",
    "    class_ = file_name[0:len(file_name)-14]\n",
    "    \n",
    "    # print(data.head(2))\n",
    "\n",
    "    columns = list(data.columns)[1:]\n",
    "    # features = ['MAV','RMS','VAR','SSI','MAX','MIN']\n",
    "    \n",
    "    vector = []\n",
    "    # global out_columns\n",
    "    \n",
    "    for item in columns:\n",
    "        temp = list(data[item])\n",
    "        # calculating MAV ***\n",
    "        # out_columns.append(item+features[0])\n",
    "        abs_val = list(map(abs,temp))\n",
    "        vector.append(np.mean(abs_val))\n",
    "\n",
    "        # calculating RMS ***\n",
    "        # out_columns.append(item+features[1])\n",
    "        vector.append(np.sqrt(np.mean(np.array(temp)**2)))\n",
    "\n",
    "        # calculate variance ***\n",
    "        # out_columns.append(item+features[2])\n",
    "        x_mean = np.mean(temp)\n",
    "        dif = temp - x_mean\n",
    "        vector.append(np.mean(np.array(dif)**2))\n",
    "\n",
    "        # calculating ssi ***\n",
    "        # out_columns.append(item+features[3])\n",
    "        vector.append(np.sum(np.array(temp)**2))\n",
    "\n",
    "        # calculating max ***\n",
    "        # out_columns.append(item+features[4])\n",
    "        vector.append(max(temp))\n",
    "\n",
    "        # calculating min ***\n",
    "        # out_columns.append(item+features[5])\n",
    "        vector.append(min(temp))\n",
    "        \n",
    "        # calculating zero crossing\n",
    "        if((item[0] == 'E') or (item[0] == 'G')):\n",
    "            vector.append(zero_crossing(temp,1))\n",
    "        elif(item[0] == 'A'):\n",
    "            vector.append(zero_crossing(temp,0.15))\n",
    "        \n",
    "    if class_ in classes:\n",
    "        vector.append(classes.index(class_))\n",
    "    else:\n",
    "        classes.append(class_)\n",
    "        vector.append(classes.index(class_))\n",
    "        \n",
    "    return vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550, 47)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = ['EMG0LMAV', 'EMG0LRMS', 'EMG0LVAR', 'EMG0LSSI', 'EMG0LMAX', 'EMG0LMIN','EMG0ZC', 'EMG1LMAV', 'EMG1LRMS', 'EMG1LVAR', 'EMG1LSSI', 'EMG1LMAX', 'EMG1LMIN','EMG1ZC', 'EMG2LMAV', 'EMG2LRMS', 'EMG2LVAR', 'EMG2LSSI', 'EMG2LMAX', 'EMG2LMIN', 'EMG2ZC','EMG3LMAV', 'EMG3LRMS', 'EMG3LVAR', 'EMG3LSSI', 'EMG3LMAX', 'EMG3LMIN', 'EMG3ZC','EMG4LMAV', 'EMG4LRMS', 'EMG4LVAR', 'EMG4LSSI', 'EMG4LMAX', 'EMG4LMIN', 'EMG4ZC','EMG5LMAV', 'EMG5LRMS', 'EMG5LVAR', 'EMG5LSSI', 'EMG5LMAX', 'EMG5LMIN', 'EMG5ZC','EMG6LMAV','EMG6LRMS', 'EMG6LVAR', 'EMG6LSSI', 'EMG6LMAX', 'EMG6LMIN', 'EMG6ZC','EMG7LMAV', 'EMG7LRMS', 'EMG7LVAR', 'EMG7LSSI', 'EMG7LMAX', 'EMG7LMIN', 'EMG7ZC','AXLMAV', 'AXLRMS', 'AXLVAR', 'AXLSSI', 'AXLMAX', 'AXLMIN', 'AXLZC','AYLMAV', 'AYLRMS', 'AYLVAR', 'AYLSSI', 'AYLMAX', 'AYLMIN', 'AYLZC','AZLMAV', 'AZLRMS', 'AZLVAR', 'AZLSSI', 'AZLMAX', 'AZLMIN', 'AZLZC','GXLMAV', 'GXLRMS', 'GXLVAR', 'GXLSSI', 'GXLMAX', 'GXLMIN', 'GXLZC','GYLMAV', 'GYLRMS', 'GYLVAR', 'GYLSSI', 'GYLMAX', 'GYLMIN', 'GYLZC','GZLMAV', 'GZLRMS', 'GZLVAR', 'GZLSSI', 'GZLMAX', 'GZLMIN', 'GZLZC','ORLMAV', 'ORLRMS', 'ORLVAR', 'ORLSSI', 'ORLMAX', 'ORLMIN', 'OPLMAV', 'OPLRMS', 'OPLVAR', 'OPLSSI', 'OPLMAX', 'OPLMIN', 'OYLMAV', 'OYLRMS', 'OYLVAR', 'OYLSSI', 'OYLMAX', 'OYLMIN', 'EMG0RMAV', 'EMG0RRMS', 'EMG0RVAR', 'EMG0RSSI', 'EMG0RMAX', 'EMG0RMIN', 'EMG0RZC', 'EMG1RMAV', 'EMG1RRMS', 'EMG1RVAR', 'EMG1RSSI', 'EMG1RMAX', 'EMG1RMIN','EMG1RZC', 'EMG2RMAV', 'EMG2RRMS', 'EMG2RVAR', 'EMG2RSSI', 'EMG2RMAX', 'EMG2RMIN','EMG2RZC', 'EMG3RMAV', 'EMG3RRMS', 'EMG3RVAR', 'EMG3RSSI', 'EMG3RMAX', 'EMG3RMIN','EMG3RZC', 'EMG4RMAV', 'EMG4RRMS', 'EMG4RVAR', 'EMG4RSSI', 'EMG4RMAX', 'EMG4RMIN','EMG4RZC', 'EMG5RMAV', 'EMG5RRMS', 'EMG5RVAR', 'EMG5RSSI', 'EMG5RMAX', 'EMG5RMIN','EMG5RZC', 'EMG6RMAV', 'EMG6RRMS', 'EMG6RVAR', 'EMG6RSSI', 'EMG6RMAX', 'EMG6RMIN','EMG6RZC', 'EMG7RMAV', 'EMG7RRMS', 'EMG7RVAR', 'EMG7RSSI', 'EMG7RMAX', 'EMG7RMIN','EMG7RZC', 'AXRMAV', 'AXRRMS', 'AXRVAR', 'AXRSSI', 'AXRMAX', 'AXRMIN','AXRZC', 'AYRMAV', 'AYRRMS', 'AYRVAR', 'AYRSSI', 'AYRMAX', 'AYRMIN','AYRZC', 'AZRMAV', 'AZRRMS', 'AZRVAR', 'AZRSSI', 'AZRMAX', 'AZRMIN','AZRZC', 'GXRMAV', 'GXRRMS', 'GXRVAR', 'GXRSSI', 'GXRMAX', 'GXRMIN','GXRZC', 'GYRMAV', 'GYRRMS', 'GYRVAR', 'GYRSSI', 'GYRMAX', 'GYRMIN','GYRZC', 'GZRMAV', 'GZRRMS', 'GZRVAR', 'GZRSSI', 'GZRMAX', 'GZRMIN','GZRZC', 'ORRMAV', 'ORRRMS', 'ORRVAR', 'ORRSSI', 'ORRMAX', 'ORRMIN', 'OPRMAV', 'OPRRMS', 'OPRVAR', 'OPRSSI', 'OPRMAX', 'OPRMIN', 'OYRMAV', 'OYRRMS', 'OYRVAR', 'OYRSSI', 'OYRMAX', 'OYRMIN','CLASS']\n",
    "# 233 columns\n",
    "selected_features = ['ORLMAX', 'OPLMAV', 'OPLRMS', 'OPLVAR', 'OPLSSI', 'OPLMIN', 'OYLMAV','OYLVAR', 'OYLMIN', 'EMG1RVAR', 'EMG1RSSI', 'EMG2RVAR', 'EMG3RMAV','EMG3RVAR', 'EMG6RMAV', 'EMG6RRMS', 'EMG7RMAV', 'AXRMAV', 'AXRRMS','AXRVAR', 'AXRSSI', 'AXRMAX', 'AYRMAV', 'AYRVAR', 'AZRMAV', 'AZRRMS','AZRVAR', 'AZRSSI', 'AZRMIN', 'GXRMAV', 'GXRRMS', 'GXRVAR', 'GXRSSI','GZRMAV', 'GZRMAX', 'GZRMIN', 'ORRMAV', 'ORRVAR', 'ORRMIN', 'OPRMAV','OPRRMS', 'OPRVAR', 'OPRSSI', 'OPRMIN', 'OYRVAR', 'OYRSSI']\n",
    "# 46 features selected from random forest\n",
    "ocolumns = ['ORLMAX', 'OPLMAV', 'OPLRMS', 'OPLVAR', 'OPLSSI', 'OPLMIN', 'OYLMAV','OYLVAR', 'OYLMIN', 'EMG1RVAR', 'EMG1RSSI', 'EMG2RVAR', 'EMG3RMAV','EMG3RVAR', 'EMG6RMAV', 'EMG6RRMS', 'EMG7RMAV', 'AXRMAV', 'AXRRMS','AXRVAR', 'AXRSSI', 'AXRMAX', 'AYRMAV', 'AYRVAR', 'AZRMAV', 'AZRRMS','AZRVAR', 'AZRSSI', 'AZRMIN', 'GXRMAV', 'GXRRMS', 'GXRVAR', 'GXRSSI','GZRMAV', 'GZRMAX', 'GZRMIN', 'ORRMAV', 'ORRVAR', 'ORRMIN', 'OPRMAV','OPRRMS', 'OPRVAR', 'OPRSSI', 'OPRMIN', 'OYRVAR', 'OYRSSI', 'CLASS']\n",
    "# 47 columns\n",
    "output = []\n",
    "classes=[]\n",
    "# print(len(out_columns))\n",
    "\n",
    "# process_one_csv(files[0])\n",
    "for k in range(1,11):\n",
    "    if(k!=5):\n",
    "        files = os.listdir('/home/amaya/emp/Realtime-Sign-Language-Translation-to-Speech-DNN/all/User'+str(k)+'/')\n",
    "    else:\n",
    "        continue\n",
    "    for file in files:\n",
    "        if(file[-1] == 'v'):      # to avoid _DS_STORE files and any other hidden files\n",
    "            output.append(process_one_csv(file,k))\n",
    "            \n",
    "initial_df = pd.DataFrame(output,columns = all_features)\n",
    "processed = initial_df[ocolumns]\n",
    "processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling of data\n",
    "scaler = preprocessing.MinMaxScaler()   # since the data set is not gaussian\n",
    "scaled_df = scaler.fit_transform(processed[ocolumns[:len(ocolumns)-1]])\n",
    "X = pd.DataFrame(scaled_df, columns = ocolumns[:len(ocolumns)-1])\n",
    "y = processed['CLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0824 04:00:28.890142 140225153967872 deprecation.py:506] From /home/amaya/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# setting up the layers\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(46,input_dim = 46,activation = 'relu'),\n",
    "    keras.layers.Dense(230,activation = 'relu'), # 450 for 232 features\n",
    "    keras.layers.Dense(20,activation = 'softmax')\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "440/440 [==============================] - 0s 269us/sample - loss: 2.9845 - acc: 0.0432\n",
      "Epoch 2/250\n",
      "440/440 [==============================] - 0s 60us/sample - loss: 2.8969 - acc: 0.1386\n",
      "Epoch 3/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 2.8091 - acc: 0.2409\n",
      "Epoch 4/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 2.7021 - acc: 0.2477\n",
      "Epoch 5/250\n",
      "440/440 [==============================] - 0s 44us/sample - loss: 2.5438 - acc: 0.3136\n",
      "Epoch 6/250\n",
      "440/440 [==============================] - 0s 44us/sample - loss: 2.3920 - acc: 0.3659\n",
      "Epoch 7/250\n",
      "440/440 [==============================] - 0s 50us/sample - loss: 2.2369 - acc: 0.4205\n",
      "Epoch 8/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 2.1057 - acc: 0.4114\n",
      "Epoch 9/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 1.9839 - acc: 0.4568\n",
      "Epoch 10/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 1.8738 - acc: 0.4932\n",
      "Epoch 11/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 1.7745 - acc: 0.5023\n",
      "Epoch 12/250\n",
      "440/440 [==============================] - 0s 53us/sample - loss: 1.6894 - acc: 0.5364\n",
      "Epoch 13/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 1.6076 - acc: 0.5636\n",
      "Epoch 14/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 1.5336 - acc: 0.5750\n",
      "Epoch 15/250\n",
      "440/440 [==============================] - 0s 49us/sample - loss: 1.4610 - acc: 0.6114\n",
      "Epoch 16/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 1.4033 - acc: 0.6068\n",
      "Epoch 17/250\n",
      "440/440 [==============================] - 0s 49us/sample - loss: 1.3748 - acc: 0.6136\n",
      "Epoch 18/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 1.3090 - acc: 0.6477\n",
      "Epoch 19/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 1.2525 - acc: 0.6545\n",
      "Epoch 20/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 1.2306 - acc: 0.6568\n",
      "Epoch 21/250\n",
      "440/440 [==============================] - 0s 49us/sample - loss: 1.1913 - acc: 0.6455\n",
      "Epoch 22/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 1.1469 - acc: 0.6773\n",
      "Epoch 23/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 1.1013 - acc: 0.7114\n",
      "Epoch 24/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 1.0708 - acc: 0.7068\n",
      "Epoch 25/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 1.0335 - acc: 0.7205\n",
      "Epoch 26/250\n",
      "440/440 [==============================] - 0s 54us/sample - loss: 1.0131 - acc: 0.7318\n",
      "Epoch 27/250\n",
      "440/440 [==============================] - 0s 49us/sample - loss: 0.9848 - acc: 0.7386\n",
      "Epoch 28/250\n",
      "440/440 [==============================] - 0s 50us/sample - loss: 0.9630 - acc: 0.7295\n",
      "Epoch 29/250\n",
      "440/440 [==============================] - 0s 54us/sample - loss: 0.9396 - acc: 0.7705\n",
      "Epoch 30/250\n",
      "440/440 [==============================] - 0s 50us/sample - loss: 0.9083 - acc: 0.7705\n",
      "Epoch 31/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.9009 - acc: 0.7659\n",
      "Epoch 32/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.8634 - acc: 0.7841\n",
      "Epoch 33/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.8386 - acc: 0.7773\n",
      "Epoch 34/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.8201 - acc: 0.7955\n",
      "Epoch 35/250\n",
      "440/440 [==============================] - 0s 44us/sample - loss: 0.8129 - acc: 0.7977\n",
      "Epoch 36/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.7932 - acc: 0.7841\n",
      "Epoch 37/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.7659 - acc: 0.8068\n",
      "Epoch 38/250\n",
      "440/440 [==============================] - 0s 70us/sample - loss: 0.7472 - acc: 0.8136\n",
      "Epoch 39/250\n",
      "440/440 [==============================] - 0s 59us/sample - loss: 0.7418 - acc: 0.8159\n",
      "Epoch 40/250\n",
      "440/440 [==============================] - 0s 57us/sample - loss: 0.7341 - acc: 0.8023\n",
      "Epoch 41/250\n",
      "440/440 [==============================] - 0s 53us/sample - loss: 0.7200 - acc: 0.8068\n",
      "Epoch 42/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.6832 - acc: 0.8409\n",
      "Epoch 43/250\n",
      "440/440 [==============================] - 0s 50us/sample - loss: 0.6632 - acc: 0.8250\n",
      "Epoch 44/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.6615 - acc: 0.8341\n",
      "Epoch 45/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.6421 - acc: 0.8432\n",
      "Epoch 46/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.6414 - acc: 0.8432\n",
      "Epoch 47/250\n",
      "440/440 [==============================] - 0s 49us/sample - loss: 0.6270 - acc: 0.8432\n",
      "Epoch 48/250\n",
      "440/440 [==============================] - 0s 50us/sample - loss: 0.6054 - acc: 0.8591\n",
      "Epoch 49/250\n",
      "440/440 [==============================] - 0s 55us/sample - loss: 0.6029 - acc: 0.8455\n",
      "Epoch 50/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.5912 - acc: 0.8591\n",
      "Epoch 51/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.5763 - acc: 0.8477\n",
      "Epoch 52/250\n",
      "440/440 [==============================] - 0s 51us/sample - loss: 0.5690 - acc: 0.8545\n",
      "Epoch 53/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.5559 - acc: 0.8682\n",
      "Epoch 54/250\n",
      "440/440 [==============================] - 0s 51us/sample - loss: 0.5384 - acc: 0.8568\n",
      "Epoch 55/250\n",
      "440/440 [==============================] - 0s 50us/sample - loss: 0.5159 - acc: 0.8818\n",
      "Epoch 56/250\n",
      "440/440 [==============================] - 0s 50us/sample - loss: 0.5223 - acc: 0.8773\n",
      "Epoch 57/250\n",
      "440/440 [==============================] - 0s 53us/sample - loss: 0.5104 - acc: 0.8727\n",
      "Epoch 58/250\n",
      "440/440 [==============================] - 0s 51us/sample - loss: 0.4942 - acc: 0.8909\n",
      "Epoch 59/250\n",
      "440/440 [==============================] - 0s 58us/sample - loss: 0.4876 - acc: 0.8795\n",
      "Epoch 60/250\n",
      "440/440 [==============================] - 0s 52us/sample - loss: 0.4766 - acc: 0.8818\n",
      "Epoch 61/250\n",
      "440/440 [==============================] - 0s 57us/sample - loss: 0.4810 - acc: 0.8841\n",
      "Epoch 62/250\n",
      "440/440 [==============================] - 0s 44us/sample - loss: 0.4575 - acc: 0.8750\n",
      "Epoch 63/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.4501 - acc: 0.8977\n",
      "Epoch 64/250\n",
      "440/440 [==============================] - 0s 55us/sample - loss: 0.4584 - acc: 0.8841\n",
      "Epoch 65/250\n",
      "440/440 [==============================] - 0s 50us/sample - loss: 0.4293 - acc: 0.8864\n",
      "Epoch 66/250\n",
      "440/440 [==============================] - 0s 70us/sample - loss: 0.4208 - acc: 0.8977\n",
      "Epoch 67/250\n",
      "440/440 [==============================] - 0s 51us/sample - loss: 0.4229 - acc: 0.9000\n",
      "Epoch 68/250\n",
      "440/440 [==============================] - 0s 50us/sample - loss: 0.4187 - acc: 0.8977\n",
      "Epoch 69/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.4094 - acc: 0.9023\n",
      "Epoch 70/250\n",
      "440/440 [==============================] - 0s 52us/sample - loss: 0.4016 - acc: 0.9091\n",
      "Epoch 71/250\n",
      "440/440 [==============================] - 0s 53us/sample - loss: 0.3793 - acc: 0.9091\n",
      "Epoch 72/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.3757 - acc: 0.9045\n",
      "Epoch 73/250\n",
      "440/440 [==============================] - 0s 51us/sample - loss: 0.3665 - acc: 0.9205\n",
      "Epoch 74/250\n",
      "440/440 [==============================] - 0s 53us/sample - loss: 0.3661 - acc: 0.9295\n",
      "Epoch 75/250\n",
      "440/440 [==============================] - 0s 71us/sample - loss: 0.3590 - acc: 0.9205\n",
      "Epoch 76/250\n",
      "440/440 [==============================] - 0s 52us/sample - loss: 0.3415 - acc: 0.9250\n",
      "Epoch 77/250\n",
      "440/440 [==============================] - 0s 44us/sample - loss: 0.3463 - acc: 0.9114\n",
      "Epoch 78/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.3398 - acc: 0.9273\n",
      "Epoch 79/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.3525 - acc: 0.9250\n",
      "Epoch 80/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.3323 - acc: 0.9250\n",
      "Epoch 81/250\n",
      "440/440 [==============================] - 0s 50us/sample - loss: 0.3132 - acc: 0.9432\n",
      "Epoch 82/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.3092 - acc: 0.9318\n",
      "Epoch 83/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.3090 - acc: 0.9386\n",
      "Epoch 84/250\n",
      "440/440 [==============================] - 0s 43us/sample - loss: 0.2992 - acc: 0.9455\n",
      "Epoch 85/250\n",
      "440/440 [==============================] - 0s 51us/sample - loss: 0.2864 - acc: 0.9591\n",
      "Epoch 86/250\n",
      "440/440 [==============================] - 0s 49us/sample - loss: 0.2909 - acc: 0.9455\n",
      "Epoch 87/250\n",
      "440/440 [==============================] - 0s 50us/sample - loss: 0.2988 - acc: 0.9386\n",
      "Epoch 88/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.2858 - acc: 0.9477\n",
      "Epoch 89/250\n",
      "440/440 [==============================] - 0s 43us/sample - loss: 0.2707 - acc: 0.9500\n",
      "Epoch 90/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.2728 - acc: 0.9523\n",
      "Epoch 91/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.2817 - acc: 0.9386\n",
      "Epoch 92/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.2672 - acc: 0.9500\n",
      "Epoch 93/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.2592 - acc: 0.9545\n",
      "Epoch 94/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.2504 - acc: 0.9568\n",
      "Epoch 95/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.2488 - acc: 0.9523\n",
      "Epoch 96/250\n",
      "440/440 [==============================] - 0s 52us/sample - loss: 0.2506 - acc: 0.9523\n",
      "Epoch 97/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.2371 - acc: 0.9545\n",
      "Epoch 98/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.2498 - acc: 0.9455\n",
      "Epoch 99/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.2332 - acc: 0.9568\n",
      "Epoch 100/250\n",
      "440/440 [==============================] - 0s 60us/sample - loss: 0.2325 - acc: 0.9636\n",
      "Epoch 101/250\n",
      "440/440 [==============================] - 0s 63us/sample - loss: 0.2304 - acc: 0.9614\n",
      "Epoch 102/250\n",
      "440/440 [==============================] - 0s 59us/sample - loss: 0.2230 - acc: 0.9636\n",
      "Epoch 103/250\n",
      "440/440 [==============================] - 0s 75us/sample - loss: 0.2115 - acc: 0.9659\n",
      "Epoch 104/250\n",
      "440/440 [==============================] - 0s 60us/sample - loss: 0.2097 - acc: 0.9568\n",
      "Epoch 105/250\n",
      "440/440 [==============================] - 0s 49us/sample - loss: 0.2100 - acc: 0.9568\n",
      "Epoch 106/250\n",
      "440/440 [==============================] - 0s 55us/sample - loss: 0.2059 - acc: 0.9614\n",
      "Epoch 107/250\n",
      "440/440 [==============================] - 0s 51us/sample - loss: 0.2119 - acc: 0.9523\n",
      "Epoch 108/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.1969 - acc: 0.9614\n",
      "Epoch 109/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.1980 - acc: 0.9682\n",
      "Epoch 110/250\n",
      "440/440 [==============================] - 0s 44us/sample - loss: 0.1901 - acc: 0.9727\n",
      "Epoch 111/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.1952 - acc: 0.9636\n",
      "Epoch 112/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.1918 - acc: 0.9636\n",
      "Epoch 113/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.1967 - acc: 0.9705\n",
      "Epoch 114/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.1828 - acc: 0.9636\n",
      "Epoch 115/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.1774 - acc: 0.9636\n",
      "Epoch 116/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.1806 - acc: 0.9614\n",
      "Epoch 117/250\n",
      "440/440 [==============================] - 0s 57us/sample - loss: 0.1818 - acc: 0.9705\n",
      "Epoch 118/250\n",
      "440/440 [==============================] - 0s 54us/sample - loss: 0.1788 - acc: 0.9614\n",
      "Epoch 119/250\n",
      "440/440 [==============================] - 0s 53us/sample - loss: 0.1658 - acc: 0.9636\n",
      "Epoch 120/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.1608 - acc: 0.9750\n",
      "Epoch 121/250\n",
      "440/440 [==============================] - 0s 44us/sample - loss: 0.1609 - acc: 0.9636\n",
      "Epoch 122/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.1611 - acc: 0.9727\n",
      "Epoch 123/250\n",
      "440/440 [==============================] - 0s 44us/sample - loss: 0.1536 - acc: 0.9750\n",
      "Epoch 124/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.1483 - acc: 0.9750\n",
      "Epoch 125/250\n",
      "440/440 [==============================] - 0s 49us/sample - loss: 0.1450 - acc: 0.9841\n",
      "Epoch 126/250\n",
      "440/440 [==============================] - 0s 52us/sample - loss: 0.1501 - acc: 0.9750\n",
      "Epoch 127/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.1568 - acc: 0.9659\n",
      "Epoch 128/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.1525 - acc: 0.9727\n",
      "Epoch 129/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.1423 - acc: 0.9795\n",
      "Epoch 130/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.1375 - acc: 0.9864\n",
      "Epoch 131/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.1352 - acc: 0.9727\n",
      "Epoch 132/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.1379 - acc: 0.9682\n",
      "Epoch 133/250\n",
      "440/440 [==============================] - 0s 49us/sample - loss: 0.1349 - acc: 0.9750\n",
      "Epoch 134/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.1268 - acc: 0.9795\n",
      "Epoch 135/250\n",
      "440/440 [==============================] - 0s 49us/sample - loss: 0.1279 - acc: 0.9795\n",
      "Epoch 136/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.1249 - acc: 0.9818\n",
      "Epoch 137/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.1271 - acc: 0.9818\n",
      "Epoch 138/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.1324 - acc: 0.9750\n",
      "Epoch 139/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.1260 - acc: 0.9773\n",
      "Epoch 140/250\n",
      "440/440 [==============================] - 0s 49us/sample - loss: 0.1165 - acc: 0.9864\n",
      "Epoch 141/250\n",
      "440/440 [==============================] - 0s 43us/sample - loss: 0.1252 - acc: 0.9750\n",
      "Epoch 142/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.1136 - acc: 0.9818\n",
      "Epoch 143/250\n",
      "440/440 [==============================] - 0s 50us/sample - loss: 0.1141 - acc: 0.9841\n",
      "Epoch 144/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.1096 - acc: 0.9841\n",
      "Epoch 145/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.1065 - acc: 0.9841\n",
      "Epoch 146/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.1073 - acc: 0.9841\n",
      "Epoch 147/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.1067 - acc: 0.9818\n",
      "Epoch 148/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.1045 - acc: 0.9886\n",
      "Epoch 149/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.1062 - acc: 0.9864\n",
      "Epoch 150/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.1013 - acc: 0.9886\n",
      "Epoch 151/250\n",
      "440/440 [==============================] - 0s 50us/sample - loss: 0.1012 - acc: 0.9841\n",
      "Epoch 152/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.1085 - acc: 0.9841\n",
      "Epoch 153/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.0974 - acc: 0.9886\n",
      "Epoch 154/250\n",
      "440/440 [==============================] - 0s 49us/sample - loss: 0.0906 - acc: 0.9886\n",
      "Epoch 155/250\n",
      "440/440 [==============================] - 0s 51us/sample - loss: 0.0915 - acc: 0.9864\n",
      "Epoch 156/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.0977 - acc: 0.9886\n",
      "Epoch 157/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.0924 - acc: 0.9841\n",
      "Epoch 158/250\n",
      "440/440 [==============================] - 0s 52us/sample - loss: 0.0948 - acc: 0.9841\n",
      "Epoch 159/250\n",
      "440/440 [==============================] - 0s 51us/sample - loss: 0.0879 - acc: 0.9886\n",
      "Epoch 160/250\n",
      "440/440 [==============================] - 0s 49us/sample - loss: 0.0850 - acc: 0.9909\n",
      "Epoch 161/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.0891 - acc: 0.9909\n",
      "Epoch 162/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.0880 - acc: 0.9886\n",
      "Epoch 163/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.0831 - acc: 0.9886\n",
      "Epoch 164/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.0848 - acc: 0.9886\n",
      "Epoch 165/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.0802 - acc: 0.9886\n",
      "Epoch 166/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.0806 - acc: 0.9909\n",
      "Epoch 167/250\n",
      "440/440 [==============================] - 0s 44us/sample - loss: 0.0791 - acc: 0.9886\n",
      "Epoch 168/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.0793 - acc: 0.9909\n",
      "Epoch 169/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.0803 - acc: 0.9886\n",
      "Epoch 170/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.0747 - acc: 0.9932\n",
      "Epoch 171/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.0814 - acc: 0.9864\n",
      "Epoch 172/250\n",
      "440/440 [==============================] - 0s 55us/sample - loss: 0.0762 - acc: 0.9909\n",
      "Epoch 173/250\n",
      "440/440 [==============================] - 0s 58us/sample - loss: 0.0759 - acc: 0.9909\n",
      "Epoch 174/250\n",
      "440/440 [==============================] - 0s 52us/sample - loss: 0.0708 - acc: 0.9955\n",
      "Epoch 175/250\n",
      "440/440 [==============================] - 0s 49us/sample - loss: 0.0724 - acc: 0.9886\n",
      "Epoch 176/250\n",
      "440/440 [==============================] - 0s 53us/sample - loss: 0.0682 - acc: 0.9932\n",
      "Epoch 177/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.0655 - acc: 0.9955\n",
      "Epoch 178/250\n",
      "440/440 [==============================] - 0s 49us/sample - loss: 0.0620 - acc: 0.9955\n",
      "Epoch 179/250\n",
      "440/440 [==============================] - 0s 61us/sample - loss: 0.0633 - acc: 0.9909\n",
      "Epoch 180/250\n",
      "440/440 [==============================] - 0s 51us/sample - loss: 0.0692 - acc: 0.9886\n",
      "Epoch 181/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.0667 - acc: 0.9932\n",
      "Epoch 182/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.0666 - acc: 0.9909\n",
      "Epoch 183/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.0620 - acc: 0.9955\n",
      "Epoch 184/250\n",
      "440/440 [==============================] - 0s 44us/sample - loss: 0.0593 - acc: 0.9955\n",
      "Epoch 185/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.0665 - acc: 0.9932\n",
      "Epoch 186/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.0597 - acc: 0.9932\n",
      "Epoch 187/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.0569 - acc: 0.9955\n",
      "Epoch 188/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.0545 - acc: 0.9977\n",
      "Epoch 189/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.0529 - acc: 0.9955\n",
      "Epoch 190/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.0544 - acc: 0.9955\n",
      "Epoch 191/250\n",
      "440/440 [==============================] - 0s 49us/sample - loss: 0.0527 - acc: 0.9977\n",
      "Epoch 192/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.0529 - acc: 0.9955\n",
      "Epoch 193/250\n",
      "440/440 [==============================] - 0s 54us/sample - loss: 0.0539 - acc: 0.9977\n",
      "Epoch 194/250\n",
      "440/440 [==============================] - 0s 60us/sample - loss: 0.0549 - acc: 0.9932\n",
      "Epoch 195/250\n",
      "440/440 [==============================] - 0s 62us/sample - loss: 0.0532 - acc: 0.9955\n",
      "Epoch 196/250\n",
      "440/440 [==============================] - 0s 61us/sample - loss: 0.0541 - acc: 0.9955\n",
      "Epoch 197/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.0487 - acc: 1.0000\n",
      "Epoch 198/250\n",
      "440/440 [==============================] - 0s 44us/sample - loss: 0.0485 - acc: 0.9977\n",
      "Epoch 199/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.0494 - acc: 0.9977\n",
      "Epoch 200/250\n",
      "440/440 [==============================] - 0s 44us/sample - loss: 0.0500 - acc: 0.9977\n",
      "Epoch 201/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.0449 - acc: 0.9977\n",
      "Epoch 202/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.0470 - acc: 0.9955\n",
      "Epoch 203/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.0445 - acc: 1.0000\n",
      "Epoch 204/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.0459 - acc: 1.0000\n",
      "Epoch 205/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.0442 - acc: 0.9955\n",
      "Epoch 206/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.0494 - acc: 0.9932\n",
      "Epoch 207/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.0437 - acc: 0.9977\n",
      "Epoch 208/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.0415 - acc: 0.9977\n",
      "Epoch 209/250\n",
      "440/440 [==============================] - 0s 43us/sample - loss: 0.0447 - acc: 0.9955\n",
      "Epoch 210/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.0431 - acc: 0.9977\n",
      "Epoch 211/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.0410 - acc: 0.9977\n",
      "Epoch 212/250\n",
      "440/440 [==============================] - 0s 50us/sample - loss: 0.0398 - acc: 1.0000\n",
      "Epoch 213/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.0387 - acc: 1.0000\n",
      "Epoch 214/250\n",
      "440/440 [==============================] - 0s 50us/sample - loss: 0.0372 - acc: 1.0000\n",
      "Epoch 215/250\n",
      "440/440 [==============================] - 0s 52us/sample - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 216/250\n",
      "440/440 [==============================] - 0s 52us/sample - loss: 0.0365 - acc: 1.0000\n",
      "Epoch 217/250\n",
      "440/440 [==============================] - 0s 54us/sample - loss: 0.0365 - acc: 0.9977\n",
      "Epoch 218/250\n",
      "440/440 [==============================] - 0s 53us/sample - loss: 0.0371 - acc: 0.9977\n",
      "Epoch 219/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.0362 - acc: 1.0000\n",
      "Epoch 220/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.0337 - acc: 1.0000\n",
      "Epoch 221/250\n",
      "440/440 [==============================] - 0s 65us/sample - loss: 0.0338 - acc: 1.0000\n",
      "Epoch 222/250\n",
      "440/440 [==============================] - 0s 60us/sample - loss: 0.0347 - acc: 0.9977\n",
      "Epoch 223/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.0339 - acc: 1.0000\n",
      "Epoch 224/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.0371 - acc: 1.0000\n",
      "Epoch 225/250\n",
      "440/440 [==============================] - 0s 43us/sample - loss: 0.0348 - acc: 1.0000\n",
      "Epoch 226/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.0350 - acc: 0.9977\n",
      "Epoch 227/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.0323 - acc: 0.9977\n",
      "Epoch 228/250\n",
      "440/440 [==============================] - 0s 44us/sample - loss: 0.0316 - acc: 1.0000\n",
      "Epoch 229/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.0318 - acc: 1.0000\n",
      "Epoch 230/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.0306 - acc: 1.0000\n",
      "Epoch 231/250\n",
      "440/440 [==============================] - 0s 44us/sample - loss: 0.0302 - acc: 1.0000\n",
      "Epoch 232/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.0302 - acc: 1.0000\n",
      "Epoch 233/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.0302 - acc: 0.9977\n",
      "Epoch 234/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.0281 - acc: 1.0000\n",
      "Epoch 235/250\n",
      "440/440 [==============================] - 0s 45us/sample - loss: 0.0296 - acc: 1.0000\n",
      "Epoch 236/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.0277 - acc: 1.0000\n",
      "Epoch 237/250\n",
      "440/440 [==============================] - 0s 56us/sample - loss: 0.0272 - acc: 1.0000\n",
      "Epoch 238/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.0271 - acc: 1.0000\n",
      "Epoch 239/250\n",
      "440/440 [==============================] - 0s 53us/sample - loss: 0.0278 - acc: 1.0000\n",
      "Epoch 240/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.0282 - acc: 1.0000\n",
      "Epoch 241/250\n",
      "440/440 [==============================] - 0s 62us/sample - loss: 0.0265 - acc: 1.0000\n",
      "Epoch 242/250\n",
      "440/440 [==============================] - 0s 51us/sample - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 243/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.0274 - acc: 1.0000\n",
      "Epoch 244/250\n",
      "440/440 [==============================] - 0s 50us/sample - loss: 0.0263 - acc: 1.0000\n",
      "Epoch 245/250\n",
      "440/440 [==============================] - 0s 49us/sample - loss: 0.0248 - acc: 1.0000\n",
      "Epoch 246/250\n",
      "440/440 [==============================] - 0s 48us/sample - loss: 0.0255 - acc: 1.0000\n",
      "Epoch 247/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.0263 - acc: 1.0000\n",
      "Epoch 248/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.0244 - acc: 1.0000\n",
      "Epoch 249/250\n",
      "440/440 [==============================] - 0s 47us/sample - loss: 0.0243 - acc: 1.0000\n",
      "Epoch 250/250\n",
      "440/440 [==============================] - 0s 46us/sample - loss: 0.0235 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f882b5fa470>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,y_train,epochs = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 0s 280us/sample - loss: 0.4732 - acc: 0.8818\n",
      "0.8818182\n"
     ]
    }
   ],
   "source": [
    "# evaluate accuracy\n",
    "test_loss,test_acc = model.evaluate(X_test,y_test)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "12\n",
      "7\n",
      "9\n",
      "11\n",
      "6\n",
      "2\n",
      "18\n",
      "18\n",
      "19\n",
      "17\n",
      "3\n",
      "17\n",
      "10\n",
      "4\n",
      "7\n",
      "7\n",
      "19\n",
      "10\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predictions = model.predict(X_test)\n",
    "for i in range(20):\n",
    "    print(np.argmax(predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "12\n",
      "7\n",
      "9\n",
      "9\n",
      "6\n",
      "2\n",
      "12\n",
      "18\n",
      "19\n",
      "17\n",
      "14\n",
      "17\n",
      "10\n",
      "4\n",
      "7\n",
      "7\n",
      "19\n",
      "10\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(list(y_test)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
